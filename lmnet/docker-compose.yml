version: '2.4'
services:
  base:
    build:
      context: ./
      dockerfile: dockerfiles/cpu.Dockerfile
      shm_size: '1gb'
    ulimits:
      memlock: -1
      stack: 67108864
    working_dir: /home/lmnet
    network_mode: "host"
    volumes:
      - ./:/home/lmnet
      - ${DATA_DIR:-/storage/dataset}:/storage/dataset
      - ${OUTPUT_DIR:-./saved}:/storage/lmnet/saved

      # In order to avoid override installed coco, Ignore to volume /home/lmnet/third_party/coco/PythonAPI
      - /home/lmnet/third_party/coco/PythonAPI

      # for x11
      - /tmp/.X11-unix:/tmp/.X11-unix
      - ~/.Xauthority:/root/.Xauthority:rw
    environment:
      - DATA_DIR=/storage/dataset
      - OUTPUT_DIR=/storage/lmnet/saved
      - PYTHONPATH=$PYTHONPATH:/home/lmnet
      # for x11
      - DISPLAY=$DISPLAY

  gpu-base:
    extends: base
    runtime: nvidia
    build:
      dockerfile: dockerfiles/gpu.Dockerfile

  tensorflow:
    extends: gpu-base
    environment:
      # Use gpu device 0 (default)
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}

  cpu-tensorflow:
    extends: base

  tensorboard:
    extends: gpu-base
    command: tensorboard --reload_interval 1 --logdir /storage/lmnet/saved/

  docs:
    extends: base
    command: ./docs/remake_docs.sh 8000
    ports:
      - "8000:8000"

  horovod:
    extends: gpu-base
    build:
      dockerfile: dockerfiles/multi-gpu.Dockerfile
    environment:
      # Use gpu device 0 (default)
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    privileged: true

  horovod-volta:
    extends: horovod
    build:
      dockerfile: dockerfiles/gpu-volta.Dockerfile
    environment:
      # Use all gpus in DGX-1, default order is optimized to run horovod
    - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-1,0,2,3,7,6,4,5}

  cyclone-v-cross:
    extends: base
    build:
      dockerfile: dockerfiles/cyclone-v-cross.Dockerfile
